{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41197db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.3.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.37.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.15.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (3.18.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.6.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.34.1)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.14.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.3.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.18.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.1.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (58.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\bharathwaj t a\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca01e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb360b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import expand_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab032b",
   "metadata": {},
   "source": [
    "img = load_img(\"Shape Dataset/Train/Circles/Circle0.jpg\")\n",
    "wordLabelCircle = img.split('.')\n",
    "print(wordLabelCircle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c729fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation=0\n",
    "while augmentation < 3:\n",
    "    \n",
    "    circleTrainDatagen = ImageDataGenerator(rotation_range=15,zoom_range=0.1,rescale=1./255)\n",
    "    CircleTrainPath=\"Shape Dataset/Train/Circle/\"\n",
    "    circleTrain = os.listdir(CircleTrainPath)\n",
    "\n",
    "    for index, image in enumerate(circleTrain):          # for loop for training images of Circle. \n",
    "        filename = image.split('.')\n",
    "        if(filename[1] == 'png' or filename[1] == 'jpg' or filename[1] == 'jpeg'):\n",
    "            # load the image using split concept.\n",
    "            img = load_img(CircleTrainPath+filename[0]+'.'+filename[1])     \n",
    "            # convert to numpy array\n",
    "            data = img_to_array(img)\n",
    "            # expand dimension to one sample\n",
    "            circleTrainSamples = expand_dims(data, axis=0)\n",
    "\n",
    "            circleTrainIT = circleTrainDatagen.flow(circleTrainSamples, batch_size=32,save_to_dir= CircleTrainPath,\n",
    "                              save_prefix=\"CIRCLE\",\n",
    "                              save_format='jpg')     #Using datagen.flow, every image is flipped horizontally, \n",
    "                                                    #rotated at certain angle and finally stored in a specified directory. \n",
    "            batch = circleTrainIT.next()\n",
    "\n",
    "        #Same concept follows for test images of Square shown below\n",
    "\n",
    "    squareTrainDatagen = ImageDataGenerator(zoom_range=0.1,rescale=1./255)\n",
    "    SquareTrainPath=\"Shape Dataset/Train/Square/\"\n",
    "    squareTrain = os.listdir(SquareTrainPath)\n",
    "\n",
    "    for index, image in enumerate(squareTrain):           \n",
    "        filename = image.split('.')\n",
    "        if(filename[1] == 'png' or filename[1] == 'jpg' or filename[1] == 'jpeg'):\n",
    "            img = load_img(SquareTrainPath+filename[0]+'.'+filename[1])\n",
    "            data = img_to_array(img)\n",
    "            squareTrainSamples = expand_dims(data, axis=0)\n",
    "            squareTrainIt = squareTrainDatagen.flow(squareTrainSamples, batch_size=32,save_to_dir= SquareTrainPath,\n",
    "                              save_prefix=\"SQUARE\",\n",
    "                              save_format='jpg')     #Using datagen.flow, every image is flipped horizontally, \n",
    "                                                    #rotated at certain angle and finally stored in a specified directory. \n",
    "            batch = squareTrainIt.next()\n",
    "    \n",
    "    augmentation+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02dd3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation=0\n",
    "while augmentation < 3:\n",
    "    \n",
    "    circleValidationDatagen = ImageDataGenerator(rotation_range=15,zoom_range=0.1,rescale=1./255)\n",
    "    CircleValidationPath=\"Shape Dataset/Validation/Circle/\"\n",
    "    circleValidation = os.listdir(CircleTrainPath)\n",
    "\n",
    "    for index, image in enumerate(circleTrain):          # for loop for training images of Circle. \n",
    "        filename = image.split('.')\n",
    "        if(filename[1] == 'png' or filename[1] == 'jpg' or filename[1] == 'jpeg'):\n",
    "            # load the image using split concept.\n",
    "            img = load_img(CircleTrainPath+filename[0]+'.'+filename[1])\n",
    "            # convert to numpy array\n",
    "            data = img_to_array(img)\n",
    "            # expand dimension to one sample\n",
    "            circleValidationSamples = expand_dims(data, axis=0)\n",
    "\n",
    "            circleValidationIT = circleValidationDatagen.flow(circleValidationSamples, batch_size=32,save_to_dir= CircleValidationPath,\n",
    "                              save_prefix=\"CIRCLE\",\n",
    "                              save_format='jpg')     #Using datagen.flow, every image is flipped horizontally, \n",
    "                                                    #rotated at certain angle and finally stored in a specified directory. \n",
    "            batch = circleValidationIT.next()\n",
    "\n",
    "        #Same concept follows for test images of Square shown below\n",
    "\n",
    "    squareValidationDatagen = ImageDataGenerator(zoom_range=0.1,rescale=1./255)\n",
    "    SquareValidationPath=\"Shape Dataset/Validation/Square/\"\n",
    "    squareValidation = os.listdir(SquareTrainPath)\n",
    "\n",
    "    for index, image in enumerate(squareTrain):           \n",
    "        filename = image.split('.')\n",
    "        if(filename[1] == 'png' or filename[1] == 'jpg' or filename[1] == 'jpeg'):\n",
    "            img = load_img(SquareTrainPath+filename[0]+'.'+filename[1])\n",
    "            data = img_to_array(img)\n",
    "            squareValidationSamples = expand_dims(data, axis=0)\n",
    "\n",
    "\n",
    "            squareValidationIt = squareValidationDatagen.flow(squareValidationSamples, batch_size=32,save_to_dir= SquareValidationPath,\n",
    "                              save_prefix=\"SQUARE\",\n",
    "                              save_format='jpg')     #Using datagen.flow, every image is flipped horizontally, \n",
    "                                                    #rotated at certain angle and finally stored in a specified directory. \n",
    "            batch = squareValidationIt.next()\n",
    "    \n",
    "    augmentation+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1d93c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 595 images belonging to 2 classes.\n",
      "Found 953 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainDatagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "testDatagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = trainDatagen.flow_from_directory(\n",
    "    \"Shape Dataset/Train\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    " \n",
    "validation_generator = testDatagen.flow_from_directory(\n",
    "    \"Shape Dataset/Validation\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db239acc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5096)              127853544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5096)              25974312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5097      \n",
      "=================================================================\n",
      "Total params: 168,547,641\n",
      "Trainable params: 153,832,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#VGG16 Architecture used for Convolution of images\n",
    "\n",
    "base_model=tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(224,224,3),\n",
    "    pooling=None\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "x=base_model.output\n",
    "\n",
    "model=Flatten()(x)\n",
    "model=Dense(units=5096,activation=\"relu\")(model)\n",
    "model=Dropout(0.5)(model)\n",
    "model=Dense(units=5096,activation=\"relu\")(model)\n",
    "output=Dense(units=1, activation=\"sigmoid\")(model)\n",
    "\n",
    "model = keras.models.Model(inputs=base_model.input, outputs = output)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7229581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6930 - accuracy: 0.6562 - val_loss: 0.6705 - val_accuracy: 0.6250\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6947 - accuracy: 0.5312 - val_loss: 0.6784 - val_accuracy: 0.5625\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6773 - accuracy: 0.5938 - val_loss: 0.7224 - val_accuracy: 0.4688\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7685 - accuracy: 0.3438 - val_loss: 0.6725 - val_accuracy: 0.6562\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7937 - accuracy: 0.4688 - val_loss: 0.6522 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7322 - accuracy: 0.5000 - val_loss: 0.7152 - val_accuracy: 0.4375\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7580 - accuracy: 0.3438 - val_loss: 0.6743 - val_accuracy: 0.6250\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6857 - accuracy: 0.5312 - val_loss: 0.6932 - val_accuracy: 0.5625\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7675 - accuracy: 0.2632 - val_loss: 0.7053 - val_accuracy: 0.4688\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6475 - accuracy: 0.6875 - val_loss: 0.7235 - val_accuracy: 0.4688\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6908 - accuracy: 0.5625 - val_loss: 0.6848 - val_accuracy: 0.5625\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.7144 - accuracy: 0.4688 - val_loss: 0.7224 - val_accuracy: 0.3750\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6975 - accuracy: 0.5000 - val_loss: 0.7018 - val_accuracy: 0.4375\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6905 - accuracy: 0.5312 - val_loss: 0.6986 - val_accuracy: 0.4375\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6810 - accuracy: 0.5938 - val_loss: 0.6897 - val_accuracy: 0.5312\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6958 - accuracy: 0.4375 - val_loss: 0.6907 - val_accuracy: 0.6250\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6873 - accuracy: 0.5938 - val_loss: 0.6896 - val_accuracy: 0.5938\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6893 - accuracy: 0.5625 - val_loss: 0.6996 - val_accuracy: 0.3125\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6884 - accuracy: 0.6562 - val_loss: 0.6948 - val_accuracy: 0.4688\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6852 - accuracy: 0.5000 - val_loss: 0.6795 - val_accuracy: 0.5938\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7075 - accuracy: 0.4062 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7050 - accuracy: 0.3750 - val_loss: 0.6887 - val_accuracy: 0.5312\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6913 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.6250\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6897 - accuracy: 0.5938 - val_loss: 0.6827 - val_accuracy: 0.5938\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6840 - accuracy: 0.5312 - val_loss: 0.6822 - val_accuracy: 0.6250\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6772 - accuracy: 0.6250 - val_loss: 0.6750 - val_accuracy: 0.6250\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6847 - accuracy: 0.5938 - val_loss: 0.7036 - val_accuracy: 0.4688\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6924 - accuracy: 0.5312 - val_loss: 0.6825 - val_accuracy: 0.5625\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6756 - accuracy: 0.6250 - val_loss: 0.6503 - val_accuracy: 0.6875\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6943 - accuracy: 0.5312 - val_loss: 0.6850 - val_accuracy: 0.5938\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6815 - accuracy: 0.5625 - val_loss: 0.6802 - val_accuracy: 0.5625\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6738 - accuracy: 0.5625 - val_loss: 0.6929 - val_accuracy: 0.3750\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6730 - accuracy: 0.5938 - val_loss: 0.7033 - val_accuracy: 0.3750\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6466 - accuracy: 0.6875 - val_loss: 0.6505 - val_accuracy: 0.6250\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6733 - accuracy: 0.5000 - val_loss: 0.7058 - val_accuracy: 0.4375\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6681 - accuracy: 0.5625 - val_loss: 0.6897 - val_accuracy: 0.5312\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6639 - accuracy: 0.5938 - val_loss: 0.6512 - val_accuracy: 0.5625\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6602 - accuracy: 0.6250 - val_loss: 0.6882 - val_accuracy: 0.4375\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7101 - accuracy: 0.5312 - val_loss: 0.6451 - val_accuracy: 0.6250\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6630 - val_accuracy: 0.6250\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6116 - accuracy: 0.7188 - val_loss: 0.7109 - val_accuracy: 0.5625\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7359 - accuracy: 0.5000 - val_loss: 0.7258 - val_accuracy: 0.4688\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6800 - accuracy: 0.5312 - val_loss: 0.6391 - val_accuracy: 0.5938\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6796 - accuracy: 0.5000 - val_loss: 0.6665 - val_accuracy: 0.6562\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6192 - accuracy: 0.6250 - val_loss: 0.6408 - val_accuracy: 0.5625\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6641 - accuracy: 0.6250 - val_loss: 0.6756 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7078 - accuracy: 0.5312 - val_loss: 0.6544 - val_accuracy: 0.5312\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6796 - accuracy: 0.5312 - val_loss: 0.6462 - val_accuracy: 0.7188\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5995 - accuracy: 0.7500 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6828 - accuracy: 0.5938 - val_loss: 0.6967 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21068596f70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(steps_per_epoch=1,generator=train_generator,validation_data=validation_generator,validation_steps=1,epochs=50,verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9dfab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 107s 6s/step - loss: 0.6602 - accuracy: 0.6134\n",
      "\n",
      "\t Accuracy\n",
      "> 61.345\n"
     ]
    }
   ],
   "source": [
    "_, trainacc = model.evaluate(train_generator, verbose=1)\n",
    "print(\"\\n\\t Accuracy\")\n",
    "print('> %.3f' % (trainacc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b99e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 175s 6s/step - loss: 0.6618 - accuracy: 0.6128\n",
      "\n",
      "\t Accuracy\n",
      "> 61.280\n"
     ]
    }
   ],
   "source": [
    "_, validationacc = model.evaluate(validation_generator, verbose=1)\n",
    "print(\"\\n\\t Accuracy\")\n",
    "print('> %.3f' % (validationacc * 100.0))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48203f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"shapes_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f9e32",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "https://stackoverflow.com/questions/62409838/error-in-loading-image-dataset-from-directory-in-tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fbeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
